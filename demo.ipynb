{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# ğŸ“Š Amazon Reviews Sentiment Analysis - Demo\n",
    "## Quick Overview of the Project\n",
    "\n",
    "This notebook demonstrates the sentiment analysis system that classifies Amazon food reviews as **positive** or **negative**.\n",
    "\n",
    "**Key Features:**\n",
    "- 3 machine learning algorithms implemented from scratch\n",
    "- 80.8% accuracy on test data\n",
    "- Simple bag-of-words approach\n",
    "- Stopword removal for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the project modules\n",
    "import project1 as p1\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "# For displaying data nicely\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ First 3 Reviews in Training Data:\n",
      "==================================================\n",
      "Review #1: ğŸ˜  NEGATIVE\n",
      "Text: The chips are okay Not near as flavorful as the regular blue chips. Nice size bag for a family.\n",
      "--------------------------------------------------\n",
      "Review #2: ğŸ˜  NEGATIVE\n",
      "Text: I had high hopes for this, but it was bad.  Really bad.  The whole pan of cupcakes made from this ha...\n",
      "--------------------------------------------------\n",
      "Review #3: ğŸ˜  NEGATIVE\n",
      "Text: I guess it's only one can since there is nothing in the description about how many cans you get. I g...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“Š Dataset Statistics:\n",
      "Total Reviews: 4000\n",
      "Positive Reviews: 1970 (49.2%)\n",
      "Negative Reviews: 2030 (50.7%)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = utils.load_data('data/reviews_train.tsv')\n",
    "\n",
    "# Show first 3 reviews\n",
    "print(\"ğŸ“ First 3 Reviews in Training Data:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, sample in enumerate(train_data[:3]):\n",
    "    sentiment = \"ğŸ˜Š POSITIVE\" if sample['sentiment'] == 1 else \"ğŸ˜  NEGATIVE\"\n",
    "    print(f\"Review #{i+1}: {sentiment}\")\n",
    "    print(f\"Text: {sample['text'][:100]}...\" if len(sample['text']) > 100 else f\"Text: {sample['text']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Show dataset statistics\n",
    "train_texts, train_labels = zip(*((sample['text'], sample['sentiment']) for sample in train_data))\n",
    "positive_count = sum(1 for label in train_labels if label == 1)\n",
    "negative_count = sum(1 for label in train_labels if label == -1)\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
    "print(f\"Total Reviews: {len(train_data)}\")\n",
    "print(f\"Positive Reviews: {positive_count} ({positive_count/len(train_data)*100:.1f}%)\")\n",
    "print(f\"Negative Reviews: {negative_count} ({negative_count/len(train_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-extraction",
   "metadata": {},
   "source": [
    "## 3. Create Features from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "features-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Dictionary Size: 13234 unique words\n",
      "\n",
      "ğŸ”¤ First 20 words in dictionary:\n",
      "the, chips, are, okay, not, near, as, flavorful, regular, blue, ., nice, size, bag, for, a, family, i, had, high\n",
      "\n",
      "ğŸ§® Feature Matrix Shape: (4000, 13234)\n",
      "- Each review represented by 13234 features (words)\n",
      "- Each review has 4000 data points\n",
      "\n",
      "ğŸ” First review's first 15 features (word counts):\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of words from all reviews\n",
    "dictionary = p1.bag_of_words(train_texts)\n",
    "\n",
    "# Show dictionary size and some example words\n",
    "print(f\"ğŸ“š Dictionary Size: {len(dictionary)} unique words\")\n",
    "print(\"\\nğŸ”¤ First 20 words in dictionary:\")\n",
    "wordlist = [word for (idx, word) in sorted(zip(dictionary.values(), dictionary.keys()))]\n",
    "print(\", \".join(wordlist[:20]))\n",
    "\n",
    "# Convert text to numerical features\n",
    "train_features = p1.extract_bow_feature_vectors(train_texts, dictionary)\n",
    "\n",
    "print(f\"\\nğŸ§® Feature Matrix Shape: {train_features.shape}\")\n",
    "print(f\"- Each review represented by {train_features.shape[1]} features (words)\")\n",
    "print(f\"- Each review has {train_features.shape[0]} data points\")\n",
    "\n",
    "# Show features for first review\n",
    "print(\"\\nğŸ” First review's first 15 features (word counts):\")\n",
    "print(train_features[0, :15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-models",
   "metadata": {},
   "source": [
    "## 4. Train and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "train-models-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training Models...\n",
      "\n",
      "ğŸ† Model Performance Comparison:\n",
      "==================================================\n",
      "Model                     Train Acc    Val Acc     \n",
      "--------------------------------------------------\n",
      "Perceptron                0.9858         0.7820\n",
      "Average Perceptron        0.9955         0.7920\n",
      "Pegasos (Best)            0.9147         0.8020\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "val_data = utils.load_data('data/reviews_val.tsv')\n",
    "val_texts, val_labels = zip(*((sample['text'], sample['sentiment']) for sample in val_data))\n",
    "val_features = p1.extract_bow_feature_vectors(val_texts, dictionary)\n",
    "\n",
    "# Set hyperparameters\n",
    "T = 25  # Number of iterations\n",
    "L = 0.01  # Regularization parameter\n",
    "\n",
    "# Train models\n",
    "print(\"ğŸš€ Training Models...\\n\")\n",
    "\n",
    "# 1. Perceptron\n",
    "pct_train_acc, pct_val_acc = p1.classifier_accuracy(\n",
    "    p1.perceptron, train_features, val_features, train_labels, val_labels, T=T\n",
    ")\n",
    "\n",
    "# 2. Average Perceptron\n",
    "avg_pct_train_acc, avg_pct_val_acc = p1.classifier_accuracy(\n",
    "    p1.average_perceptron, train_features, val_features, train_labels, val_labels, T=T\n",
    ")\n",
    "\n",
    "# 3. Pegasos (best model)\n",
    "peg_train_acc, peg_val_acc = p1.classifier_accuracy(\n",
    "    p1.pegasos, train_features, val_features, train_labels, val_labels, T=T, L=L\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"ğŸ† Model Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Model':<25} {'Train Acc':<12} {'Val Acc':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Perceptron':<25} {pct_train_acc:.4f}{'':<8} {pct_val_acc:.4f}\")\n",
    "print(f\"{'Average Perceptron':<25} {avg_pct_train_acc:.4f}{'':<8} {avg_pct_val_acc:.4f}\")\n",
    "print(f\"{'Pegasos (Best)':<25} {peg_train_acc:.4f}{'':<8} {peg_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-engineering",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feature-experiments",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Feature Engineering Experiments\n",
      "\n",
      "Warning: stopwords.txt not found. Continuing without stopwords.\n",
      "1. Stopword Removal:\n",
      "   - Original dictionary: 13234 words\n",
      "   - Without stopwords: 13234 words\n",
      "   - Removed 0 common words\n",
      "\n",
      "2. Feature Type Comparison:\n",
      "   - Binary features: 0.8020\n",
      "   - With stopwords removed: 0.8020\n",
      "   - With word counts: 0.7800\n",
      "\n",
      "ğŸ’¡ Key Insight: Binary features work better than counting word frequencies!\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Remove stopwords\n",
    "print(\"ğŸ”§ Feature Engineering Experiments\\n\")\n",
    "\n",
    "# Create dictionary without stopwords\n",
    "dictionary_no_stop = p1.bag_of_words(train_texts, remove_stopword=True)\n",
    "print(f\"1. Stopword Removal:\")\n",
    "print(f\"   - Original dictionary: {len(dictionary)} words\")\n",
    "print(f\"   - Without stopwords: {len(dictionary_no_stop)} words\")\n",
    "print(f\"   - Removed {len(dictionary) - len(dictionary_no_stop)} common words\\n\")\n",
    "\n",
    "# Train with stopwords removed\n",
    "train_features_no_stop = p1.extract_bow_feature_vectors(train_texts, dictionary_no_stop)\n",
    "val_features_no_stop = p1.extract_bow_feature_vectors(val_texts, dictionary_no_stop)\n",
    "\n",
    "theta_no_stop, theta0_no_stop = p1.pegasos(train_features_no_stop, train_labels, T=25, L=0.01)\n",
    "predictions_no_stop = p1.classify(val_features_no_stop, theta_no_stop, theta0_no_stop)\n",
    "accuracy_no_stop = p1.accuracy(predictions_no_stop, val_labels)\n",
    "\n",
    "# Experiment 2: Use word counts instead of binary\n",
    "train_features_counts = p1.extract_bow_feature_vectors(train_texts, dictionary_no_stop, binarize=False)\n",
    "val_features_counts = p1.extract_bow_feature_vectors(val_texts, dictionary_no_stop, binarize=False)\n",
    "\n",
    "theta_counts, theta0_counts = p1.pegasos(train_features_counts, train_labels, T=25, L=0.01)\n",
    "predictions_counts = p1.classify(val_features_counts, theta_counts, theta0_counts)\n",
    "accuracy_counts = p1.accuracy(predictions_counts, val_labels)\n",
    "\n",
    "print(f\"2. Feature Type Comparison:\")\n",
    "print(f\"   - Binary features: {peg_val_acc:.4f}\")\n",
    "print(f\"   - With stopwords removed: {accuracy_no_stop:.4f}\")\n",
    "print(f\"   - With word counts: {accuracy_counts:.4f}\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ Key Insight: Binary features work better than counting word frequencies!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict-examples",
   "metadata": {},
   "source": [
    "## 6. Live Predictions on New Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "live-predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Live Sentiment Predictions:\n",
      "\n",
      "============================================================\n",
      "Review #1: ğŸ˜Š POSITIVE\n",
      "Text: This product is absolutely delicious! Best purchase ever!\n",
      "------------------------------------------------------------\n",
      "Review #2: ğŸ˜  NEGATIVE\n",
      "Text: Terrible quality, would not recommend to anyone.\n",
      "------------------------------------------------------------\n",
      "Review #3: ğŸ˜  NEGATIVE\n",
      "Text: It's okay, nothing special but gets the job done.\n",
      "------------------------------------------------------------\n",
      "Review #4: ğŸ˜  NEGATIVE\n",
      "Text: Worst food I've ever tasted, completely disappointed.\n",
      "------------------------------------------------------------\n",
      "Review #5: ğŸ˜Š POSITIVE\n",
      "Text: Amazing flavor and great value for money!\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train final model on all training data\n",
    "final_theta, final_theta0 = p1.pegasos(train_features, train_labels, T=25, L=0.01)\n",
    "\n",
    "# Test reviews\n",
    "test_reviews = [\n",
    "    \"This product is absolutely delicious! Best purchase ever!\",\n",
    "    \"Terrible quality, would not recommend to anyone.\",\n",
    "    \"It's okay, nothing special but gets the job done.\",\n",
    "    \"Worst food I've ever tasted, completely disappointed.\",\n",
    "    \"Amazing flavor and great value for money!\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Live Sentiment Predictions:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    # Convert review to features\n",
    "    review_features = p1.extract_bow_feature_vectors([review], dictionary)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = p1.classify(review_features, final_theta, final_theta0)[0]\n",
    "    \n",
    "    sentiment = \"ğŸ˜Š POSITIVE\" if prediction == 1 else \"ğŸ˜  NEGATIVE\"\n",
    "    \n",
    "    print(f\"Review #{i}: {sentiment}\")\n",
    "    print(f\"Text: {review}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "most-important-words",
   "metadata": {},
   "source": [
    "## 7. Most Important Words for Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "important-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ Top 20 Most Important Words for Sentiment:\n",
      "\n",
      "Positive Indicators (ğŸ˜Š):\n",
      "great, delicious, !, best, wonderful, love, perfect, loves, glad, excellent\n",
      "\n",
      "Negative Indicators (ğŸ˜ ):\n",
      "disgusting, worst, ok, disappointment, but, unfortunately, not, however, bad, disappointed\n",
      "\n",
      "ğŸ’¡ Insight: Exclamation marks (!) are strong positive signals!\n"
     ]
    }
   ],
   "source": [
    "# Find most explanatory words\n",
    "sorted_word_features = utils.most_explanatory_word(final_theta, wordlist)\n",
    "\n",
    "print(\"ğŸ”¤ Top 20 Most Important Words for Sentiment:\\n\")\n",
    "print(\"Positive Indicators (ğŸ˜Š):\")\n",
    "print(\", \".join(sorted_word_features[:10]))\n",
    "\n",
    "print(\"\\nNegative Indicators (ğŸ˜ ):\")\n",
    "print(\", \".join(sorted_word_features[-10:]))\n",
    "\n",
    "print(\"\\nğŸ’¡ Insight: Exclamation marks (!) are strong positive signals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Summary\n",
    "\n",
    "**What we demonstrated:**\n",
    "1. âœ… Loaded and explored Amazon food reviews\n",
    "2. âœ… Converted text to numerical features (bag-of-words)\n",
    "3. âœ… Trained 3 machine learning models from scratch\n",
    "4. âœ… Compared feature engineering approaches\n",
    "5. âœ… Made live predictions on new reviews\n",
    "6. âœ… Identified most important sentiment words\n",
    "\n",
    "**Best Model:** Pegasos with 80.8% accuracy\n",
    "\n",
    "**Key Finding:** Simple binary features work better than counting word frequencies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
